#try: 
## 5, 1-1.5, 2048, 1.0e-4
## 15, 10, 2048, 1.0e-4
## 30, 1-15, 2048, 3.0e-4 
## 30, 1, 2048, 3.0e-4 


dataset:
  train_json_path: "./HNC/hnc_clean_strict_train.json"
  # train_json_path: "./HNC/hnc_train_sampled_1_percent.json"
  image_folder_path: "./gqa_dataset/images/images"

training:
  model_name: "openai/clip-vit-base-patch32"
  num_epochs: 10
  learning_rate: 1.0e-4
  weight_decay: 0.05
  num_warmup_steps: 500
  temperature: 0.07
  hard_negative_weight: 10
  dynamic_hard_negative: false
  hard_negative_max_weight: 3
  l2_reg_weight: 1.0e-2
  
lora:
  lora_r: 8
  lora_alpha: 16
  lora_dropout: 0.1

deepspeed:
  config:
    train_batch_size: 2048
    train_micro_batch_size_per_gpu: 256
    gradient_accumulation_steps: 2
    gradient_checkpointing: false
    gradient_clipping: 1.0
    fp16:
      enabled: true
      initial_scale_power: 12
      hysteresis: 5
      dynamic_loss_scale: true
    zero_optimization:
      stage: 2


misc:
  repo_name: "HNC_2048_lora"

